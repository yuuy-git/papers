# [On the Importance of Label Quality for Semantic Segmentation](http://openaccess.thecvf.com/content_cvpr_2018/html/Zlateski_On_the_Importance_CVPR_2018_paper.html)

####  Category
Semantic Segmentation
アノテーション(ラベル)に関して議論

#### Context
* 背景  
Segmentationのアノテーションってすごくコストがかかる  
1pxごとに正解ラベルを塗る作業、、  
* 最近の流れ  
細かいラベル付けができるようになる研究が盛ん。アノテーションコストを下げながらクオリティをあげるやつ。  
 
#### Correctness  
実務で感じてたことを論文にしてくれた感じ  
割と本当に思っていたので、アイデアで終わらず実験までして、論文という形で公開できればなあと思う  

#### Contributions  
* 正解ラベルクオリティーとCNNセグメンテーションのパフォーマンスとの関係性を調査  
* CNNセグメンテーションのパフォーマンスは正解ラベルに費やした時間(=いかに丁寧にラベリングするか)に依存している  
* 少ないデータでもきちんとアノテーションすれば、大量に雑にアノテーションするのと同じくらいの精度は出る  
* 粗いラベル付けで事前学習させたものを、きちんとアノテーションしたデータ少数を用いて学習させたとき、大量のきちんと塗ってあるデータで学習させたものと同等かそれよりも良い精度が出た。  

####  Clarity  
読みやすい。  

#### コメント  
  大量の粗いデータセットと少ないデータセットを用いて学習させれば精度が良くなる？ということ？  
  ならば、  
  ①丁寧なアノテーションで学習する。  
  ②丁寧なアノテーションで学習したものでいろんな画像を予測ストックしておく。(rawdata labeldata)  
  ③②を用いて１から学習する。  
  ④③でできたモデルを①を用いてファインチューニングする  
  みたいなサイクルを回せばどんどん良くなるということなのか？これは発見では？実験したい。詳しく読む。
